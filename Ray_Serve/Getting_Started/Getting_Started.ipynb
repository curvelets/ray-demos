{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c06b810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.ray.io/en/latest/serve/getting_started.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3eb0366",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ray[serve] in /home/ray/anaconda3/lib/python3.9/site-packages (2.2.0)\n",
      "Requirement already satisfied: transformers in /home/ray/anaconda3/lib/python3.9/site-packages (4.25.1)\n",
      "Requirement already satisfied: requests in /home/ray/anaconda3/lib/python3.9/site-packages (2.27.1)\n",
      "Requirement already satisfied: torch in /home/ray/anaconda3/lib/python3.9/site-packages (1.13.0)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /home/ray/anaconda3/lib/python3.9/site-packages (from ray[serve]) (3.20.3)\n",
      "Requirement already satisfied: attrs in /home/ray/anaconda3/lib/python3.9/site-packages (from ray[serve]) (22.1.0)\n",
      "Requirement already satisfied: virtualenv>=20.0.24 in /home/ray/anaconda3/lib/python3.9/site-packages (from ray[serve]) (20.17.1)\n",
      "Requirement already satisfied: grpcio>=1.32.0 in /home/ray/anaconda3/lib/python3.9/site-packages (from ray[serve]) (1.51.1)\n",
      "Requirement already satisfied: click>=7.0 in /home/ray/anaconda3/lib/python3.9/site-packages (from ray[serve]) (8.1.3)\n",
      "Requirement already satisfied: frozenlist in /home/ray/anaconda3/lib/python3.9/site-packages (from ray[serve]) (1.3.3)\n",
      "Requirement already satisfied: jsonschema in /home/ray/anaconda3/lib/python3.9/site-packages (from ray[serve]) (4.17.3)\n",
      "Requirement already satisfied: pyyaml in /home/ray/anaconda3/lib/python3.9/site-packages (from ray[serve]) (5.4.1)\n",
      "Requirement already satisfied: aiosignal in /home/ray/anaconda3/lib/python3.9/site-packages (from ray[serve]) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.19.3 in /home/ray/anaconda3/lib/python3.9/site-packages (from ray[serve]) (1.23.5)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /home/ray/anaconda3/lib/python3.9/site-packages (from ray[serve]) (1.0.4)\n",
      "Requirement already satisfied: filelock in /home/ray/anaconda3/lib/python3.9/site-packages (from ray[serve]) (3.8.2)\n",
      "Requirement already satisfied: opencensus in /home/ray/anaconda3/lib/python3.9/site-packages (from ray[serve]) (0.11.0)\n",
      "Requirement already satisfied: uvicorn in /home/ray/anaconda3/lib/python3.9/site-packages (from ray[serve]) (0.20.0)\n",
      "Requirement already satisfied: pydantic in /home/ray/anaconda3/lib/python3.9/site-packages (from ray[serve]) (1.10.2)\n",
      "Requirement already satisfied: prometheus-client<0.14.0,>=0.7.1 in /home/ray/anaconda3/lib/python3.9/site-packages (from ray[serve]) (0.13.1)\n",
      "Requirement already satisfied: gpustat>=1.0.0 in /home/ray/anaconda3/lib/python3.9/site-packages (from ray[serve]) (1.0.0)\n",
      "Requirement already satisfied: colorful in /home/ray/anaconda3/lib/python3.9/site-packages (from ray[serve]) (0.5.5)\n",
      "Requirement already satisfied: fastapi in /home/ray/anaconda3/lib/python3.9/site-packages (from ray[serve]) (0.88.0)\n",
      "Requirement already satisfied: aiohttp-cors in /home/ray/anaconda3/lib/python3.9/site-packages (from ray[serve]) (0.7.0)\n",
      "Requirement already satisfied: aiorwlock in /home/ray/anaconda3/lib/python3.9/site-packages (from ray[serve]) (1.3.0)\n",
      "Requirement already satisfied: starlette in /home/ray/anaconda3/lib/python3.9/site-packages (from ray[serve]) (0.22.0)\n",
      "Requirement already satisfied: aiohttp>=3.7 in /home/ray/anaconda3/lib/python3.9/site-packages (from ray[serve]) (3.8.3)\n",
      "Requirement already satisfied: smart-open in /home/ray/anaconda3/lib/python3.9/site-packages (from ray[serve]) (6.2.0)\n",
      "Requirement already satisfied: py-spy>=0.2.0 in /home/ray/anaconda3/lib/python3.9/site-packages (from ray[serve]) (0.3.14)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ray/anaconda3/lib/python3.9/site-packages (from transformers) (4.63.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ray/anaconda3/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ray/anaconda3/lib/python3.9/site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /home/ray/anaconda3/lib/python3.9/site-packages (from transformers) (0.11.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/ray/anaconda3/lib/python3.9/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ray/anaconda3/lib/python3.9/site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ray/anaconda3/lib/python3.9/site-packages (from requests) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ray/anaconda3/lib/python3.9/site-packages (from requests) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ray/anaconda3/lib/python3.9/site-packages (from requests) (3.3)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/ray/anaconda3/lib/python3.9/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/ray/anaconda3/lib/python3.9/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: typing-extensions in /home/ray/anaconda3/lib/python3.9/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/ray/anaconda3/lib/python3.9/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/ray/anaconda3/lib/python3.9/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: wheel in /home/ray/anaconda3/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.37.1)\n",
      "Requirement already satisfied: setuptools in /home/ray/anaconda3/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (61.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/ray/anaconda3/lib/python3.9/site-packages (from aiohttp>=3.7->ray[serve]) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ray/anaconda3/lib/python3.9/site-packages (from aiohttp>=3.7->ray[serve]) (1.8.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ray/anaconda3/lib/python3.9/site-packages (from aiohttp>=3.7->ray[serve]) (6.0.3)\n",
      "Requirement already satisfied: nvidia-ml-py<=11.495.46,>=11.450.129 in /home/ray/anaconda3/lib/python3.9/site-packages (from gpustat>=1.0.0->ray[serve]) (11.495.46)\n",
      "Requirement already satisfied: psutil>=5.6.0 in /home/ray/anaconda3/lib/python3.9/site-packages (from gpustat>=1.0.0->ray[serve]) (5.9.4)\n",
      "Requirement already satisfied: six>=1.7 in /home/ray/anaconda3/lib/python3.9/site-packages (from gpustat>=1.0.0->ray[serve]) (1.13.0)\n",
      "Requirement already satisfied: blessed>=1.17.1 in /home/ray/anaconda3/lib/python3.9/site-packages (from gpustat>=1.0.0->ray[serve]) (1.19.1)\n",
      "Requirement already satisfied: wcwidth>=0.1.4 in /home/ray/anaconda3/lib/python3.9/site-packages (from blessed>=1.17.1->gpustat>=1.0.0->ray[serve]) (0.2.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ray/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: platformdirs<3,>=2.4 in /home/ray/anaconda3/lib/python3.9/site-packages (from virtualenv>=20.0.24->ray[serve]) (2.6.0)\n",
      "Requirement already satisfied: distlib<1,>=0.3.6 in /home/ray/anaconda3/lib/python3.9/site-packages (from virtualenv>=20.0.24->ray[serve]) (0.3.6)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /home/ray/anaconda3/lib/python3.9/site-packages (from starlette->ray[serve]) (3.6.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ray/anaconda3/lib/python3.9/site-packages (from anyio<5,>=3.4.0->starlette->ray[serve]) (1.3.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /home/ray/anaconda3/lib/python3.9/site-packages (from jsonschema->ray[serve]) (0.19.2)\n",
      "Requirement already satisfied: opencensus-context>=0.1.3 in /home/ray/anaconda3/lib/python3.9/site-packages (from opencensus->ray[serve]) (0.1.3)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /home/ray/anaconda3/lib/python3.9/site-packages (from opencensus->ray[serve]) (2.11.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /home/ray/anaconda3/lib/python3.9/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[serve]) (1.57.0)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=2.14.1 in /home/ray/anaconda3/lib/python3.9/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[serve]) (2.15.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ray/anaconda3/lib/python3.9/site-packages (from google-auth<3.0dev,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[serve]) (4.7.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/ray/anaconda3/lib/python3.9/site-packages (from google-auth<3.0dev,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[serve]) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ray/anaconda3/lib/python3.9/site-packages (from google-auth<3.0dev,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[serve]) (0.2.8)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ray/anaconda3/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[serve]) (0.4.8)\n",
      "Requirement already satisfied: h11>=0.8 in /home/ray/anaconda3/lib/python3.9/site-packages (from uvicorn->ray[serve]) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install \"ray[serve]\" transformers requests torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa8ce53",
   "metadata": {},
   "source": [
    "# Local version before Ray Serve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "459b826b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ray/anaconda3/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading: 100%|██████████| 242M/242M [00:06<00:00, 40.3MB/s] \n",
      "Downloading: 100%|██████████| 792k/792k [00:00<00:00, 1.78MB/s]\n",
      "Downloading: 100%|██████████| 1.39M/1.39M [00:00<00:00, 3.18MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour monde!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ray/anaconda3/lib/python3.9/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# File name: model.py\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "class Translator:\n",
    "    def __init__(self):\n",
    "        # Load model\n",
    "        self.model = pipeline(\"translation_en_to_fr\", model=\"t5-small\")\n",
    "\n",
    "    def translate(self, text: str) -> str:\n",
    "        # Run inference\n",
    "        model_output = self.model(text)\n",
    "\n",
    "        # Post-process output to return only the translation text\n",
    "        translation = model_output[0][\"translation_text\"]\n",
    "\n",
    "        return translation\n",
    "\n",
    "\n",
    "translator = Translator()\n",
    "\n",
    "translation = translator.translate(\"Hello world!\")\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283b8999",
   "metadata": {},
   "source": [
    "# Serve the model with Ray Serve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ed36e8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@serve.deployment(num_replicas=2, ray_actor_options={\"num_cpus\": 0.2, \"num_gpus\": 0})\n",
    "class Translator:\n",
    "    def __init__(self):\n",
    "        # Load model\n",
    "        self.model = pipeline(\"translation_en_to_fr\", model=\"t5-small\")\n",
    "\n",
    "    def translate(self, text: str) -> str:\n",
    "        # Run inference\n",
    "        model_output = self.model(text)\n",
    "\n",
    "        # Post-process output to return only the translation text\n",
    "        translation = model_output[0][\"translation_text\"]\n",
    "\n",
    "        return translation\n",
    "\n",
    "    async def __call__(self, http_request: Request) -> str:\n",
    "        english_text: str = await http_request.json()\n",
    "        return self.translate(english_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2adea997",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(ServeController pid=334880) INFO 2022-12-13 19:06:53,199 controller 334880 deployment_state.py:1310 - Adding 1 replica to deployment 'Translator'.\n",
      "(ServeController pid=334880) INFO 2022-12-13 19:06:57,666 controller 334880 deployment_state.py:1214 - Stopping 1 replicas of deployment 'Translator' with outdated versions.\n",
      "(ServeController pid=334880) INFO 2022-12-13 19:06:59,831 controller 334880 deployment_state.py:1310 - Adding 1 replica to deployment 'Translator'.\n",
      "(ServeController pid=334880) INFO 2022-12-13 19:07:04,261 controller 334880 deployment_state.py:1336 - Removing 1 replica from deployment 'Summarizer'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RayServeSyncHandle(deployment='Translator')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run following command from CLI\n",
    "#serve run serve_deployment:translator\n",
    "translator = Translator.bind()\n",
    "serve.run(translator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "056b7c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour monde!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(HTTPProxyActor pid=334924) INFO 2022-12-13 19:07:07,418 http_proxy 10.0.63.8 http_proxy.py:361 - POST / 200 212.8ms\n",
      "(ServeReplica:Translator pid=336416) INFO 2022-12-13 19:07:07,417 Translator Translator#PLOWuY replica.py:505 - HANDLE __call__ OK 208.0ms\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "english_text = \"Hello world!\"\n",
    "\n",
    "response = requests.post(\"http://127.0.0.1:8000/\", json=english_text)\n",
    "french_text = response.text\n",
    "\n",
    "print(french_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "61dcb75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(ServeController pid=334880) INFO 2022-12-13 19:08:24,250 controller 334880 deployment_state.py:1336 - Removing 2 replicas from deployment 'Translator'.\n"
     ]
    }
   ],
   "source": [
    "serve.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f488949e",
   "metadata": {},
   "source": [
    "# Composing Machine Learning Models with Deployment Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "66af86e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it was the best of times, it was worst of times .\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "class Summarizer:\n",
    "    def __init__(self):\n",
    "        # Load model\n",
    "        self.model = pipeline(\"summarization\", model=\"t5-small\")\n",
    "\n",
    "    def summarize(self, text: str) -> str:\n",
    "        # Run inference\n",
    "        model_output = self.model(text, min_length=5, max_length=15)\n",
    "\n",
    "        # Post-process output to return only the summary text\n",
    "        summary = model_output[0][\"summary_text\"]\n",
    "\n",
    "        return summary\n",
    "\n",
    "\n",
    "summarizer = Summarizer()\n",
    "\n",
    "summary = summarizer.summarize(\n",
    "    \"It was the best of times, it was the worst of times, it was the age \"\n",
    "    \"of wisdom, it was the age of foolishness, it was the epoch of belief\"\n",
    ")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c8943500",
   "metadata": {},
   "outputs": [],
   "source": [
    "@serve.deployment\n",
    "class Translator:\n",
    "    def __init__(self):\n",
    "        # Load model\n",
    "        self.model = pipeline(\"translation_en_to_fr\", model=\"t5-small\")\n",
    "\n",
    "    def translate(self, text: str) -> str:\n",
    "        # Run inference\n",
    "        model_output = self.model(text)\n",
    "\n",
    "        # Post-process output to return only the translation text\n",
    "        translation = model_output[0][\"translation_text\"]\n",
    "\n",
    "        return translation\n",
    "\n",
    "\n",
    "@serve.deployment\n",
    "class Summarizer:\n",
    "    def __init__(self, translator):\n",
    "        # Load model\n",
    "        self.model = pipeline(\"summarization\", model=\"t5-small\")\n",
    "        self.translator = translator\n",
    "\n",
    "    def summarize(self, text: str) -> str:\n",
    "        # Run inference\n",
    "        model_output = self.model(text, min_length=5, max_length=15)\n",
    "\n",
    "        # Post-process output to return only the summary text\n",
    "        summary = model_output[0][\"summary_text\"]\n",
    "\n",
    "        return summary\n",
    "\n",
    "    async def __call__(self, http_request: Request) -> str:\n",
    "        english_text: str = await http_request.json()\n",
    "        summary = self.summarize(english_text)\n",
    "        print(summary,type(summary))\n",
    "        translation_ref = await self.translator.translate.remote(summary)\n",
    "        #translation = ray.get(translation_ref)\n",
    "        translation = await translation_ref\n",
    "        return translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bdd18028",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(ServeController pid=337163) INFO 2022-12-13 19:09:56,631 controller 337163 http_state.py:129 - Starting HTTP proxy with name 'SERVE_CONTROLLER_ACTOR:SERVE_PROXY_ACTOR-ab3314cb20f8ef656d173f3786b63fec5ade73b79f63643f522bb198' on node 'ab3314cb20f8ef656d173f3786b63fec5ade73b79f63643f522bb198' listening on '127.0.0.1:8000'\n",
      "(HTTPProxyActor pid=337207) INFO:     Started server process [337207]\n",
      "(ServeController pid=337163) INFO 2022-12-13 19:09:58,283 controller 337163 deployment_state.py:1310 - Adding 1 replica to deployment 'Translator'.\n",
      "(ServeController pid=337163) INFO 2022-12-13 19:09:58,301 controller 337163 deployment_state.py:1310 - Adding 1 replica to deployment 'Summarizer'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RayServeSyncHandle(deployment='Summarizer')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run following CLI in term\n",
    "#!serve run graph:deployment_graph\n",
    "summarizer = Summarizer.bind(Translator.bind())\n",
    "serve.run(summarizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fa4879f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ServeReplica:Summarizer pid=337257) it was the best of times, it was worst of times . <class 'str'>\n",
      "c'était le meilleur des temps, c'était le pire des temps .\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "english_text = (\n",
    "    \"It was the best of times, it was the worst of times, it was the age \"\n",
    "    \"of wisdom, it was the age of foolishness, it was the epoch of belief\"\n",
    ")\n",
    "response = requests.post(\"http://127.0.0.1:8000/\", json=english_text)\n",
    "french_text = response.text\n",
    "\n",
    "print(french_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dd23c277",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(HTTPProxyActor pid=337207) INFO 2022-12-13 19:10:04,854 http_proxy 10.0.63.8 http_proxy.py:361 - POST / 200 1567.5ms\n",
      "(ServeReplica:Translator pid=337256) INFO 2022-12-13 19:10:04,851 Translator Translator#leTUjQ replica.py:505 - HANDLE translate OK 914.5ms\n",
      "(ServeReplica:Summarizer pid=337257) INFO 2022-12-13 19:10:04,852 Summarizer Summarizer#ZIxqhd replica.py:505 - HANDLE __call__ OK 1562.5ms\n",
      "(ServeController pid=337163) INFO 2022-12-13 19:10:04,883 controller 337163 deployment_state.py:1336 - Removing 1 replica from deployment 'Translator'.\n",
      "(ServeController pid=337163) INFO 2022-12-13 19:10:04,886 controller 337163 deployment_state.py:1336 - Removing 1 replica from deployment 'Summarizer'.\n"
     ]
    }
   ],
   "source": [
    "serve.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20bf39d",
   "metadata": {},
   "source": [
    "# To test .deploy() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6571e11b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "54efd876",
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = Summarizer.bind(Translator.bind())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9d74022d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ray.dag.class_node.ClassNode"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Translator.bind())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "085ccc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ServeReplica:Summarizer pid=335866) it was the best of times, it was worst of times . <class 'str'>\n",
      "c'était le meilleur des temps, c'était le pire des temps .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(HTTPProxyActor pid=334924) INFO 2022-12-13 19:04:42,720 http_proxy 10.0.63.8 http_proxy.py:361 - POST / 200 1499.7ms\n",
      "(ServeReplica:Translator pid=335823) INFO 2022-12-13 19:04:42,717 Translator Translator#jChlNT replica.py:505 - HANDLE translate OK 897.4ms\n",
      "(ServeReplica:Summarizer pid=335866) INFO 2022-12-13 19:04:42,719 Summarizer Summarizer#sJqdGy replica.py:505 - HANDLE __call__ OK 1494.5ms\n"
     ]
    }
   ],
   "source": [
    "english_text = (\n",
    "    \"It was the best of times, it was the worst of times, it was the age \"\n",
    "    \"of wisdom, it was the age of foolishness, it was the epoch of belief\"\n",
    ")\n",
    "response = requests.post(\"http://127.0.0.1:8000/\", json=english_text)\n",
    "french_text = response.text\n",
    "\n",
    "print(french_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d8c5b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
