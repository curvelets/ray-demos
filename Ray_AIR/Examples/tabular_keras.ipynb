{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94cfc3f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.5 MB)\n",
      "     |████████████████████████████████| 9.5 MB 5.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /home/ray/anaconda3/lib/python3.9/site-packages (from scikit-learn) (1.23.5)\n",
      "Collecting joblib>=1.1.1\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "     |████████████████████████████████| 297 kB 109.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.3.2 in /home/ray/anaconda3/lib/python3.9/site-packages (from scikit-learn) (1.9.3)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.2.0 scikit-learn-1.2.0 threadpoolctl-3.1.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install --user \"tensorflow>=2.8.0\"\n",
    "!pip install --user \"scikit-learn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55c75212",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-19 08:48:46,259\tINFO worker.py:1230 -- Using address localhost:9031 set in the environment variable RAY_ADDRESS\n",
      "2022-12-19 08:48:46,520\tINFO worker.py:1352 -- Connecting to existing Ray cluster at address: 10.0.7.140:9031...\n",
      "2022-12-19 08:48:46,529\tINFO worker.py:1529 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32mhttps://console.anyscale.com/api/v2/sessions/ses_buwxbm99nq8dryqg6p8sbytw/services?redirect_to=dashboard \u001b[39m\u001b[22m\n",
      "2022-12-19 08:48:46,534\tINFO packaging.py:546 -- Creating a file package for local directory '.'.\n",
      "2022-12-19 08:48:46,537\tINFO packaging.py:373 -- Pushing file package 'gcs://_ray_pkg_64f7bff8f540b0eb.zip' (0.14MiB) to Ray cluster...\n",
      "2022-12-19 08:48:46,539\tINFO packaging.py:386 -- Successfully pushed file package 'gcs://_ray_pkg_64f7bff8f540b0eb.zip'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.9.12</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.2.0</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://console.anyscale.com/api/v2/sessions/ses_buwxbm99nq8dryqg6p8sbytw/services?redirect_to=dashboard\" target=\"_blank\">http://console.anyscale.com/api/v2/sessions/ses_buwxbm99nq8dryqg6p8sbytw/services?redirect_to=dashboard</a></b></td>\n",
       "</tr>\n",
       "\n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='console.anyscale.com/api/v2/sessions/ses_buwxbm99nq8dryqg6p8sbytw/services?redirect_to=dashboard', python_version='3.9.12', ray_version='2.2.0', ray_commit='b6af0887ee5f2e460202133791ad941a41f15beb', address_info={'node_ip_address': '10.0.7.140', 'raylet_ip_address': '10.0.7.140', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2022-12-19_08-36-51_309384_211/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-12-19_08-36-51_309384_211/sockets/raylet', 'webui_url': 'console.anyscale.com/api/v2/sessions/ses_buwxbm99nq8dryqg6p8sbytw/services?redirect_to=dashboard', 'session_dir': '/tmp/ray/session_2022-12-19_08-36-51_309384_211', 'metrics_export_port': 50477, 'gcs_address': '10.0.7.140:9031', 'address': '10.0.7.140:9031', 'dashboard_agent_listen_port': 52365, 'node_id': 'de6187171ed3603eaa1ff6f2b892d34e6142d8769fd54d626724975c'})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "runtime_env = {\n",
    "    \"working_dir\": \".\",\n",
    "    \"excludes\":['/data/','/.ipynb_checkpoints/']\n",
    "}\n",
    "ray.init(runtime_env=runtime_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77cf8b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CPU': 8.0,\n",
      " 'memory': 18155232462.0,\n",
      " 'node:10.0.7.140': 1.0,\n",
      " 'object_store_memory': 9077616230.0}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(ray.cluster_resources())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34c347d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "INPUT = \"input\"\n",
    "LABEL = \"is_big_tip\"\n",
    "\n",
    "def get_data() -> pd.DataFrame:\n",
    "    \"\"\"Fetch the taxi fare data to work on.\"\"\"\n",
    "    _data = pd.read_csv(\n",
    "        \"https://raw.githubusercontent.com/tensorflow/tfx/master/\"\n",
    "        \"tfx/examples/chicago_taxi_pipeline/data/simple/data.csv\"\n",
    "    )\n",
    "    _data[LABEL] = _data[\"tips\"] / _data[\"fare\"] > 0.2\n",
    "    # We drop some columns here for the sake of simplicity.\n",
    "    return _data.drop(\n",
    "        [\n",
    "            \"tips\",\n",
    "            \"fare\",\n",
    "            \"dropoff_latitude\",\n",
    "            \"dropoff_longitude\",\n",
    "            \"pickup_latitude\",\n",
    "            \"pickup_longitude\",\n",
    "            \"pickup_census_tract\",\n",
    "        ],\n",
    "        axis=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24a82a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_community_area</th>\n",
       "      <th>trip_start_month</th>\n",
       "      <th>trip_start_hour</th>\n",
       "      <th>trip_start_day</th>\n",
       "      <th>trip_start_timestamp</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>dropoff_census_tract</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>company</th>\n",
       "      <th>trip_seconds</th>\n",
       "      <th>dropoff_community_area</th>\n",
       "      <th>is_big_tip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>1400269500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Chicago Elite Cab Corp. (Chicago Carriag</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>1362683700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Chicago Elite Cab Corp.</td>\n",
       "      <td>300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1380593700</td>\n",
       "      <td>12.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>Taxi Affiliation Services</td>\n",
       "      <td>1380.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1382319000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>Taxi Affiliation Services</td>\n",
       "      <td>180.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1369897200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>Dispatch Taxi Affiliation</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pickup_community_area  trip_start_month  trip_start_hour  trip_start_day  \\\n",
       "0                    NaN                 5               19               6   \n",
       "1                    NaN                 3               19               5   \n",
       "2                   60.0                10                2               3   \n",
       "3                   10.0                10                1               2   \n",
       "4                   14.0                 5                7               5   \n",
       "\n",
       "   trip_start_timestamp  trip_miles  dropoff_census_tract payment_type  \\\n",
       "0            1400269500         0.0                   NaN  Credit Card   \n",
       "1            1362683700         0.0                   NaN      Unknown   \n",
       "2            1380593700        12.6                   NaN         Cash   \n",
       "3            1382319000         0.0                   NaN         Cash   \n",
       "4            1369897200         0.0                   NaN         Cash   \n",
       "\n",
       "                                    company  trip_seconds  \\\n",
       "0  Chicago Elite Cab Corp. (Chicago Carriag           0.0   \n",
       "1                   Chicago Elite Cab Corp.         300.0   \n",
       "2                 Taxi Affiliation Services        1380.0   \n",
       "3                 Taxi Affiliation Services         180.0   \n",
       "4                 Dispatch Taxi Affiliation        1080.0   \n",
       "\n",
       "   dropoff_community_area  is_big_tip  \n",
       "0                     NaN       False  \n",
       "1                     NaN       False  \n",
       "2                     NaN       False  \n",
       "3                     NaN       False  \n",
       "4                     NaN       False  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = get_data()\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38e215c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 11251 samples for training and 3751 samples for testing.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "def split_data(data: pd.DataFrame) -> Tuple[ray.data.Dataset, pd.DataFrame, np.array]:\n",
    "    \"\"\"Split the data in a stratified way.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing train dataset, test data and test label.\n",
    "    \"\"\"\n",
    "    # There is a native offering in Ray Dataset for split as well.\n",
    "    # However, supporting stratification is a TODO there. So use\n",
    "    # scikit-learn equivalent here.\n",
    "    train_data, test_data = train_test_split(\n",
    "        data, stratify=data[[LABEL]], random_state=1113\n",
    "    )\n",
    "    _train_ds = ray.data.from_pandas(train_data)\n",
    "    _test_label = test_data[LABEL].values\n",
    "    _test_df = test_data.drop([LABEL], axis=1)\n",
    "    return _train_ds, _test_df, _test_label\n",
    "\n",
    "train_ds, test_df, test_label = split_data(data)\n",
    "print(f\"There are {train_ds.count()} samples for training and {test_df.shape[0]} samples for testing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "364ce0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.data.preprocessors import (\n",
    "    BatchMapper,\n",
    "    Chain,\n",
    "    OneHotEncoder,\n",
    "    SimpleImputer,\n",
    ")\n",
    "\n",
    "def get_preprocessor():\n",
    "    \"\"\"Construct a chain of preprocessors.\"\"\"\n",
    "    imputer1 = SimpleImputer(\n",
    "        [\"dropoff_census_tract\"], strategy=\"most_frequent\"\n",
    "    )\n",
    "    imputer2 = SimpleImputer(\n",
    "        [\"pickup_community_area\", \"dropoff_community_area\"],\n",
    "        strategy=\"most_frequent\",\n",
    "    )\n",
    "    imputer3 = SimpleImputer([\"payment_type\"], strategy=\"most_frequent\")\n",
    "    imputer4 = SimpleImputer(\n",
    "        [\"company\"], strategy=\"most_frequent\")\n",
    "    imputer5 = SimpleImputer(\n",
    "        [\"trip_start_timestamp\", \"trip_miles\", \"trip_seconds\"], strategy=\"mean\"\n",
    "    )\n",
    "\n",
    "    ohe = OneHotEncoder(\n",
    "        columns=[\n",
    "            \"trip_start_hour\",\n",
    "            \"trip_start_day\",\n",
    "            \"trip_start_month\",\n",
    "            \"dropoff_census_tract\",\n",
    "            \"pickup_community_area\",\n",
    "            \"dropoff_community_area\",\n",
    "            \"payment_type\",\n",
    "            \"company\",\n",
    "        ],\n",
    "        max_categories={\n",
    "            \"dropoff_census_tract\": 25,\n",
    "            \"pickup_community_area\": 20,\n",
    "            \"dropoff_community_area\": 20,\n",
    "            \"payment_type\": 2,\n",
    "            \"company\": 7,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    def batch_mapper_fn(df):\n",
    "        df[\"trip_start_year\"] = pd.to_datetime(df[\"trip_start_timestamp\"], unit=\"s\").dt.year\n",
    "        df = df.drop([\"trip_start_timestamp\"], axis=1)\n",
    "        return df\n",
    "\n",
    "    def concat_for_tensor(dataframe):\n",
    "        from ray.data.extensions import TensorArray\n",
    "        result = {}\n",
    "        feature_cols = [col for col in dataframe.columns if col != LABEL]\n",
    "        result[INPUT] = TensorArray(dataframe[feature_cols].to_numpy(dtype=np.float32))\n",
    "        if LABEL in dataframe.columns:\n",
    "            result[LABEL] = dataframe[LABEL]\n",
    "        return  pd.DataFrame(result)\n",
    "\n",
    "    chained_pp = Chain(\n",
    "        imputer1,\n",
    "        imputer2,\n",
    "        imputer3,\n",
    "        imputer4,\n",
    "        imputer5,\n",
    "        ohe,\n",
    "        BatchMapper(batch_mapper_fn, batch_format=\"pandas\"),\n",
    "        BatchMapper(concat_for_tensor, batch_format=\"pandas\")\n",
    "    )\n",
    "    return chained_pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "930ce8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that `INPUT_SIZE` here is corresponding to the output dimension\n",
    "# of the previously defined processing steps.\n",
    "# This is used to specify the input shape of Keras model.\n",
    "INPUT_SIZE = 120\n",
    "# The training batch size. Based on `NUM_WORKERS`, each worker\n",
    "# will get its own share of this batch size. For example, if\n",
    "# `NUM_WORKERS = 2`, each worker will work on 4 samples per batch.\n",
    "BATCH_SIZE = 8\n",
    "# Number of epoch. Adjust it based on how quickly you want the run to be.\n",
    "EPOCH = 1\n",
    "# Number of training workers.\n",
    "# Adjust this accordingly based on the resources you have!\n",
    "NUM_WORKERS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9919434",
   "metadata": {},
   "source": [
    "# Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4a50db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-19 10:29:18.627573: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-19 10:29:22.116166: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-19 10:29:22.116188: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-19 10:29:31.774059: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-19 10:29:31.775832: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-19 10:29:31.775842: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def build_model():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.Input(shape=(INPUT_SIZE,)))\n",
    "    model.add(tf.keras.layers.Dense(50, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "873f2422",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.air import session, Checkpoint\n",
    "from ray.train.tensorflow import TensorflowCheckpoint\n",
    "\n",
    "def train_loop_per_worker():\n",
    "    dataset_shard = session.get_dataset_shard(\"train\")\n",
    "\n",
    "    strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n",
    "    with strategy.scope():\n",
    "        model = build_model()\n",
    "        model.compile(\n",
    "            loss=\"binary_crossentropy\",\n",
    "            optimizer=\"adam\",\n",
    "            metrics=[\"accuracy\"],\n",
    "        )\n",
    "\n",
    "    for epoch in range(EPOCH):            \n",
    "        tf_dataset = dataset_shard.to_tf(feature_columns=INPUT, label_columns=LABEL, batch_size=BATCH_SIZE, drop_last=True)\n",
    "\n",
    "        model.fit(tf_dataset, verbose=0)\n",
    "        # This saves checkpoint in a way that can be used by Ray Serve coherently.\n",
    "        session.report(\n",
    "            {},\n",
    "            checkpoint=TensorflowCheckpoint.from_model(model),\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc3ac045",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ray/anaconda3/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2022-12-19 10:59:33</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:54.30        </td></tr>\n",
       "<tr><td>Memory:      </td><td>3.3/30.9 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/16.91 GiB heap, 0.0/8.45 GiB objects\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc             </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  _timestamp</th><th style=\"text-align: right;\">  _time_this_iter_s</th><th style=\"text-align: right;\">  _training_iteration</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TensorflowTrainer_1ea52_00000</td><td>TERMINATED</td><td>10.0.7.140:30179</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">          34.606</td><td style=\"text-align: right;\">  1671476369</td><td style=\"text-align: right;\">            20.2285</td><td style=\"text-align: right;\">                    1</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(pid=30179) 2022-12-19 10:58:41.422374: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "(pid=30179) To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "(pid=30179) 2022-12-19 10:58:41.599689: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "(pid=30179) 2022-12-19 10:58:41.599728: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "(pid=30179) 2022-12-19 10:58:46.457945: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "(pid=30179) 2022-12-19 10:58:46.458076: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "(pid=30179) 2022-12-19 10:58:46.458100: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "(RayTrainWorker pid=30342) 2022-12-19 10:59:01.394998: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "(RayTrainWorker pid=30342) To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "(RayTrainWorker pid=30343) 2022-12-19 10:59:01.394999: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "(RayTrainWorker pid=30343) To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "(RayTrainWorker pid=30342) 2022-12-19 10:59:01.532256: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "(RayTrainWorker pid=30342) 2022-12-19 10:59:01.532341: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "(RayTrainWorker pid=30343) 2022-12-19 10:59:01.532279: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "(RayTrainWorker pid=30343) 2022-12-19 10:59:01.532308: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "(RayTrainWorker pid=30342) 2022-12-19 10:59:04.964112: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "(RayTrainWorker pid=30342) 2022-12-19 10:59:04.964209: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "(RayTrainWorker pid=30342) 2022-12-19 10:59:04.964223: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "(RayTrainWorker pid=30343) 2022-12-19 10:59:04.944965: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "(RayTrainWorker pid=30343) 2022-12-19 10:59:04.945062: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "(RayTrainWorker pid=30343) 2022-12-19 10:59:04.945080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "(RayTrainWorker pid=30342) WARNING:tensorflow:From /tmp/ipykernel_1892/2418762265.py:7: _CollectiveAllReduceStrategyExperimental.__init__ (from tensorflow.python.distribute.collective_all_reduce_strategy) is deprecated and will be removed in a future version.\n",
      "(RayTrainWorker pid=30342) Instructions for updating:\n",
      "(RayTrainWorker pid=30342) use distribute.MultiWorkerMirroredStrategy instead\n",
      "(RayTrainWorker pid=30342) 2022-12-19 10:59:09.727989: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "(RayTrainWorker pid=30342) 2022-12-19 10:59:09.731819: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "(RayTrainWorker pid=30342) 2022-12-19 10:59:09.731875: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-0-7-140): /proc/driver/nvidia/version does not exist\n",
      "(RayTrainWorker pid=30342) 2022-12-19 10:59:09.747224: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "(RayTrainWorker pid=30342) To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "(RayTrainWorker pid=30343) WARNING:tensorflow:From /tmp/ipykernel_1892/2418762265.py:7: _CollectiveAllReduceStrategyExperimental.__init__ (from tensorflow.python.distribute.collective_all_reduce_strategy) is deprecated and will be removed in a future version.\n",
      "(RayTrainWorker pid=30343) Instructions for updating:\n",
      "(RayTrainWorker pid=30343) use distribute.MultiWorkerMirroredStrategy instead\n",
      "(RayTrainWorker pid=30343) 2022-12-19 10:59:09.729143: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "(RayTrainWorker pid=30343) 2022-12-19 10:59:09.731823: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "(RayTrainWorker pid=30343) 2022-12-19 10:59:09.731878: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-0-7-140): /proc/driver/nvidia/version does not exist\n",
      "(RayTrainWorker pid=30343) 2022-12-19 10:59:09.747216: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "(RayTrainWorker pid=30343) To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "(RayTrainWorker pid=30342) 2022-12-19 10:59:09.908805: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:447] Started server with target: grpc://10.0.7.140:51181\n",
      "(RayTrainWorker pid=30343) 2022-12-19 10:59:09.909307: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:447] Started server with target: grpc://10.0.7.140:59625\n",
      "(RayTrainWorker pid=30342) 2022-12-19 10:59:09.964584: I tensorflow/core/distributed_runtime/coordination/coordination_service.cc:502] /job:worker/replica:0/task:1 has connected to coordination service. Incarnation: 12856595358761841475\n",
      "(RayTrainWorker pid=30342) 2022-12-19 10:59:09.964664: I tensorflow/core/distributed_runtime/coordination/coordination_service.cc:502] /job:worker/replica:0/task:0 has connected to coordination service. Incarnation: 18341099211431838025\n",
      "(RayTrainWorker pid=30342) 2022-12-19 10:59:09.969387: I tensorflow/core/distributed_runtime/coordination/coordination_service_agent.cc:277] Coordination agent has successfully connected.\n",
      "(RayTrainWorker pid=30343) 2022-12-19 10:59:09.969329: I tensorflow/core/distributed_runtime/coordination/coordination_service_agent.cc:277] Coordination agent has successfully connected.\n",
      "(RayTrainWorker pid=30342) 2022-12-19 10:59:11.080408: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "(RayTrainWorker pid=30343) 2022-12-19 10:59:11.080323: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th style=\"text-align: right;\">  _time_this_iter_s</th><th style=\"text-align: right;\">  _timestamp</th><th style=\"text-align: right;\">  _training_iteration</th><th>date               </th><th>done  </th><th>episodes_total  </th><th>experiment_id                   </th><th style=\"text-align: right;\">  experiment_tag</th><th>hostname     </th><th style=\"text-align: right;\">  iterations_since_restore</th><th>node_ip   </th><th style=\"text-align: right;\">  pid</th><th>should_checkpoint  </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th>timesteps_total  </th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TensorflowTrainer_1ea52_00000</td><td style=\"text-align: right;\">            20.2285</td><td style=\"text-align: right;\">  1671476369</td><td style=\"text-align: right;\">                    1</td><td>2022-12-19_10-59-30</td><td>True  </td><td>                </td><td>4d9e5f8df04e49a297d89c4cf977437a</td><td style=\"text-align: right;\">               0</td><td>ip-10-0-7-140</td><td style=\"text-align: right;\">                         1</td><td>10.0.7.140</td><td style=\"text-align: right;\">30179</td><td>True               </td><td style=\"text-align: right;\">              34.606</td><td style=\"text-align: right;\">            34.606</td><td style=\"text-align: right;\">        34.606</td><td style=\"text-align: right;\"> 1671476370</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>1ea52_00000</td><td style=\"text-align: right;\">    0.0104268</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-19 10:59:33,161\tINFO tune.py:762 -- Total run time: 66.42 seconds (54.29 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "from ray.train.tensorflow import TensorflowTrainer\n",
    "from ray.air.config import ScalingConfig\n",
    "\n",
    "trainer = TensorflowTrainer(\n",
    "    train_loop_per_worker=train_loop_per_worker,\n",
    "    scaling_config=ScalingConfig(num_workers=NUM_WORKERS),\n",
    "    datasets={\"train\": train_ds},\n",
    "    preprocessor=get_preprocessor(),\n",
    ")\n",
    "result = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5f8c8f",
   "metadata": {},
   "source": [
    "# Serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d242f281",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import Request\n",
    "\n",
    "async def dataframe_adapter(request: Request):\n",
    "    \"\"\"Serve HTTP Adapter that reads JSON and converts to pandas DataFrame.\"\"\"\n",
    "    content = await request.json()\n",
    "    return pd.DataFrame.from_dict(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c00c71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import serve\n",
    "from ray.air.checkpoint import Checkpoint\n",
    "from ray.train.tensorflow import TensorflowPredictor\n",
    "from ray.serve import PredictorDeployment\n",
    "\n",
    "\n",
    "def serve_model(checkpoint: Checkpoint, model_definition, adapter, name=\"Model\") -> str:\n",
    "    \"\"\"Expose a serve endpoint.\n",
    "\n",
    "    Returns:\n",
    "        serve URL.\n",
    "    \"\"\"\n",
    "    serve.run(\n",
    "        PredictorDeployment.options(name=name).bind(\n",
    "            TensorflowPredictor,\n",
    "            checkpoint,\n",
    "            batching_params=dict(max_batch_size=2, batch_wait_timeout_s=5),\n",
    "            model_definition=model_definition,\n",
    "            http_adapter=adapter,\n",
    "        )\n",
    "    )\n",
    "    return f\"http://localhost:8000/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d85a4879",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(ServeController pid=32331) INFO 2022-12-19 11:06:16,518 controller 32331 http_state.py:129 - Starting HTTP proxy with name 'SERVE_CONTROLLER_ACTOR:SERVE_PROXY_ACTOR-de6187171ed3603eaa1ff6f2b892d34e6142d8769fd54d626724975c' on node 'de6187171ed3603eaa1ff6f2b892d34e6142d8769fd54d626724975c' listening on '127.0.0.1:8000'\n",
      "(HTTPProxyActor pid=32379) INFO:     Started server process [32379]\n",
      "(ServeController pid=32331) INFO 2022-12-19 11:06:18,778 controller 32331 deployment_state.py:1310 - Adding 1 replica to deployment 'Model'.\n",
      "(ServeReplica:Model pid=32425) 2022-12-19 11:06:20.936481: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "(ServeReplica:Model pid=32425) To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "(ServeReplica:Model pid=32425) 2022-12-19 11:06:21.083073: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "(ServeReplica:Model pid=32425) 2022-12-19 11:06:21.083109: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "(ServeReplica:Model pid=32425) 2022-12-19 11:06:25.539064: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "(ServeReplica:Model pid=32425) 2022-12-19 11:06:25.539149: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "(ServeReplica:Model pid=32425) 2022-12-19 11:06:25.539163: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "(ServeReplica:Model pid=32425) 2022-12-19 11:06:32.913259: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "(ServeReplica:Model pid=32425) 2022-12-19 11:06:32.913292: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "(ServeReplica:Model pid=32425) 2022-12-19 11:06:32.913309: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-0-7-140): /proc/driver/nvidia/version does not exist\n",
      "(ServeReplica:Model pid=32425) 2022-12-19 11:06:32.913525: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "(ServeReplica:Model pid=32425) To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "# Generally speaking, training and serving are done in totally different ray clusters.\n",
    "# To simulate that, let's shutdown the old ray cluster in preparation for serving.\n",
    "#ray.shutdown()\n",
    "\n",
    "endpoint_uri = serve_model(result.checkpoint, build_model, dataframe_adapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "26e5e614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "request0 prediction: [0.0001859385083662346] - label: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(HTTPProxyActor pid=32379) INFO 2022-12-19 11:06:39,969 http_proxy 10.0.7.140 http_proxy.py:361 - POST / 200 5161.2ms\n",
      "(ServeReplica:Model pid=32425) INFO 2022-12-19 11:06:39,958 Model Model#rgTZgm replica.py:505 - HANDLE __call__ OK 5147.3ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "request1 prediction: [2.9279172508722695e-07] - label: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(HTTPProxyActor pid=32379) INFO 2022-12-19 11:06:45,059 http_proxy 10.0.7.140 http_proxy.py:361 - POST / 200 5088.4ms\n",
      "(ServeReplica:Model pid=32425) INFO 2022-12-19 11:06:45,057 Model Model#rgTZgm replica.py:505 - HANDLE __call__ OK 5084.3ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "request2 prediction: [3.692715324632445e-07] - label: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(HTTPProxyActor pid=32379) INFO 2022-12-19 11:06:50,174 http_proxy 10.0.7.140 http_proxy.py:361 - POST / 200 5109.4ms\n",
      "(ServeReplica:Model pid=32425) INFO 2022-12-19 11:06:50,172 Model Model#rgTZgm replica.py:505 - HANDLE __call__ OK 5105.8ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "request3 prediction: [5.959282134426758e-08] - label: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(HTTPProxyActor pid=32379) INFO 2022-12-19 11:06:55,263 http_proxy 10.0.7.140 http_proxy.py:361 - POST / 200 5082.7ms\n",
      "(ServeReplica:Model pid=32425) INFO 2022-12-19 11:06:55,261 Model Model#rgTZgm replica.py:505 - HANDLE __call__ OK 5079.2ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "request4 prediction: [8.020435871003428e-08] - label: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(HTTPProxyActor pid=32379) INFO 2022-12-19 11:07:00,354 http_proxy 10.0.7.140 http_proxy.py:361 - POST / 200 5086.0ms\n",
      "(ServeReplica:Model pid=32425) INFO 2022-12-19 11:07:00,352 Model Model#rgTZgm replica.py:505 - HANDLE __call__ OK 5082.9ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "request5 prediction: [1.6037300554216927e-07] - label: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(HTTPProxyActor pid=32379) INFO 2022-12-19 11:07:05,445 http_proxy 10.0.7.140 http_proxy.py:361 - POST / 200 5087.1ms\n",
      "(ServeReplica:Model pid=32425) INFO 2022-12-19 11:07:05,444 Model Model#rgTZgm replica.py:505 - HANDLE __call__ OK 5084.1ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "request6 prediction: [1.2155658168921946e-07] - label: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(HTTPProxyActor pid=32379) INFO 2022-12-19 11:07:10,547 http_proxy 10.0.7.140 http_proxy.py:361 - POST / 200 5097.7ms\n",
      "(ServeReplica:Model pid=32425) INFO 2022-12-19 11:07:10,546 Model Model#rgTZgm replica.py:505 - HANDLE __call__ OK 5094.6ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "request7 prediction: [6.367843070620438e-07] - label: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(HTTPProxyActor pid=32379) INFO 2022-12-19 11:07:15,661 http_proxy 10.0.7.140 http_proxy.py:361 - POST / 200 5108.4ms\n",
      "(ServeReplica:Model pid=32425) INFO 2022-12-19 11:07:15,659 Model Model#rgTZgm replica.py:505 - HANDLE __call__ OK 5104.9ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "request8 prediction: [8.011139840391479e-08] - label: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(HTTPProxyActor pid=32379) INFO 2022-12-19 11:07:20,771 http_proxy 10.0.7.140 http_proxy.py:361 - POST / 200 5104.3ms\n",
      "(ServeReplica:Model pid=32425) INFO 2022-12-19 11:07:20,769 Model Model#rgTZgm replica.py:505 - HANDLE __call__ OK 5100.5ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "request9 prediction: [1.0172703696298413e-05] - label: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(HTTPProxyActor pid=32379) INFO 2022-12-19 11:07:25,882 http_proxy 10.0.7.140 http_proxy.py:361 - POST / 200 5104.9ms\n",
      "(ServeReplica:Model pid=32425) INFO 2022-12-19 11:07:25,880 Model Model#rgTZgm replica.py:505 - HANDLE __call__ OK 5100.8ms\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "NUM_SERVE_REQUESTS = 10\n",
    "\n",
    "def send_requests(df: pd.DataFrame, label: np.array):\n",
    "    for i in range(NUM_SERVE_REQUESTS):\n",
    "        one_row = df.iloc[[i]].to_dict()\n",
    "        serve_result = requests.post(endpoint_uri, data=json.dumps(one_row), headers={\"Content-Type\": \"application/json\"}).json()\n",
    "        print(\n",
    "            f\"request{i} prediction: {serve_result[0]['predictions']} \"\n",
    "            f\"- label: {str(label[i])}\"\n",
    "        )\n",
    "        \n",
    "send_requests(test_df, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd18124b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
